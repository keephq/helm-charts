namespace: keep
serviceAccount:
  create: true
  annotations: {}
  name: ""
nameOverride: ""
fullnameOverride: ""
isGKE: false

global:
  # this section controls the ingress resource at nginx-ingress.yaml
  ingress:
    enabled: true
    # Keep supports both nginx and haproxy ingress controllers
    className: "nginx"
    # this is for cases where you want nginx configuration but the nginx className is different.
    classType: ""
    annotations: {}
    # this is the prefix for the websocket route
    # so the full url will be <ingress-host>/websocket
    websocketPrefix: "/websocket"
    # can't use /api since its "catched" by the nextjs frontend e.g
    #   . /api/auth/signin or /api/config
    backendPrefix: "/v2"
    # this is the prefix for the frontend route
    # so the full url will be <ingress-host>/
    frontendPrefix: "/"
    # to set the ingress host
    hosts: []
    # uncomment when you want to use a custom domain
    # hosts:
    #  - host: keep.example.com

    # this is the list of TLS certificates to use
    tls: []
    # uncomment when you want to use a custom domain with TLS
    # tls:
    #   - hosts:
    #       - keep.example.com
    #    secretName: keep-tls

# Additional labels that should be applied to all resources
additionalLabels:
  {}
  # app: keep

backend:
  # if true, the backend will be enabled
  enabled: true
  # if true, wait for the database to be ready before starting the API
  # if you use external database, you can set this to false
  waitForDatabase:
    enabled: true
    port: 3306
    # port: 5432
  # if true, the database connection string will be read from a secret
  # if it is false, the DATABASE_CONNECTION_STRING value can be set directly
  databaseConnectionStringFromSecret:
    enabled: false
    secretName: ""
    secretKey: ""
  env:
    - name: DATABASE_CONNECTION_STRING
      value: mysql+pymysql://root@keep-database:3306/keep
      # value: postgresql+psycopg2://postgres:mysecretpassword@keep-database:5432/keep
    - name: DATABASE_NAME
      value: keep-database
    - name: SECRET_MANAGER_TYPE
      value: k8s
    - name: PORT
      value: "8080"
    - name: PUSHER_APP_ID
      value: 1
    - name: PUSHER_APP_KEY
      value: keepappkey
    - name: PUSHER_APP_SECRET
      value: keepappsecret
    - name: PUSHER_HOST
      value: keep-websocket
    - name: PUSHER_PORT
      value: 6001
    - name: PROMETHEUS_MULTIPROC_DIR
      value: "/tmp/prometheus"
  # -- Name of the secret to include
  envFromSecret: ""

  # -- Sensible environment variables will be rendered as a new secret object; escape {{ in secret values to avoid Helm interpretation.
  envRenderSecret: {}

  # -- List of secrets to include. Must include name and can be marked as optional.
  envFromSecrets: []
  # - name: keep-secret-name
  #   prefix: prefix
  #   optional: true

  # -- configmaps to include. Must include name and can be marked as optional.
  # each entry should contain a name key, and can optionally specify whether the configmap must be defined with an optional key.
  envFromConfigMaps: []
  # - name: keep-env-configmap-name
  #   prefix: prefix
  #   optional: true
  openAiApi:
    enabled: false
    openAiApiKey: ""
  replicaCount: 1
  image:
    repository: us-central1-docker.pkg.dev/keephq/keep/keep-api
    pullPolicy: Always
  extraInitContainers: []
  imagePullSecrets: []
  podAnnotations:
    "prometheus.io/scrape": "true"
    "prometheus.io/path": "/metrics/processing"
    "prometheus.io/port": "8080"
  podSecurityContext: {}
  securityContext: {}
  service:
    type: ClusterIP
    port: 8080
  # for openshit
  route:
    enabled: false
    host: chart-example-backend.local
    path: /
    tls: []
    wildcardPolicy: None
  # GKE healthcheck config
  backendConfig:
    healthCheck:
      checkIntervalSec: 30
      timeoutSec: 10
      healthyThreshold: 1
      unhealthyThreshold: 3
      path: "/docs"
      port: 8080
      type: HTTP
  resources: {}
  # resources:
  #   limits:
  #     cpu: 3000m
  #     memory: 2Gi
  #   requests:
  #     cpu: 1500m
  #     memory: 512Mi
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 3
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80
  nodeSelector: {}
  topologySpreadConstraints: []
  tolerations: []
  affinity: {}
  healthCheck:
    enabled: false
    probes:
      readinessProbe:
        tcpSocket:
          port: 8080
        initialDelaySeconds: 30
        periodSeconds: 10
      livenessProbe:
        tcpSocket:
          port: 8080
  extraVolumeMounts: []
  extraVolumes: []
  # override the default command
  # command:
  #   - "gunicorn"
  # override the default args
  # args:
  #   - "keep.api.api:get_app"
  #   - "--bind"
  #   - "0.0.0.0:8080"
  #   - "--workers"
  #   - "4"
  #   - "-k"
  #   - "uvicorn.workers.UvicornWorker"
  #   - "-c"
  #   - "/venv/lib/python3.11/site-packages/keep/api/config.py"
  #   - "--preload"
  #   - "--access-logfile"
  #   - "/tmp/accesslog"
  #   - "--error-logfile"
  #   - "/tmp/errorlog"
  #   - "--log-level"
  #   - "debug"
  #   - "--access-logformat"
  #   - "%(t)s %(h)s \"%(r)s\" %(s)s %(b)s \"%(f)s\" \"%(a)s\" %(L)s"

frontend:
  enabled: true
  env:
    - name: NEXTAUTH_SECRET
      value: secret
    # Shahar: took me whole day to figure out that I need to set this to 1
    # https://github.com/nextauthjs/next-auth/issues/600
    - name: VERCEL
      value: 1
    - name: ENV
      value: development
    - name: NODE_ENV
      value: development
    - name: HOSTNAME
      value: 0.0.0.0
    - name: PUSHER_APP_KEY
      value: "keepappkey"
  # -- Name of the secret to include
  envFromSecret: ""

  # -- Sensible environment variables will be rendered as a new secret object; escape {{ in secret values to avoid Helm interpretation.
  envRenderSecret: {}

  # -- List of secrets to include. Must include name and can be marked as optional.
  envFromSecrets: []
  # - name: keep-secret-name
  #   prefix: prefix
  #   optional: true

  # -- Configmaps to include. Must include name and can be marked as optional.
  # each entry should contain a name key, and can optionally specify whether the configmap must be defined with an optional key.
  envFromConfigMaps: []
  # - name: keep-env-configmap-name
  #   prefix: prefix
  #   optional: true
  replicaCount: 1
  image:
    repository: us-central1-docker.pkg.dev/keephq/keep/keep-ui
    pullPolicy: Always
  imagePullSecrets: []
  serviceAccount:
    create: true
    annotations: {}
    name: ""
  podAnnotations: {}
  podSecurityContext: {}
  securityContext: {}
  service:
    type: ClusterIP
    port: 3000
  # for openshit
  route:
    enabled: false
    host: chart-example.local
    path: /
    tls: []
    wildcardPolicy: None
  # GKE healthcheck config
  backendConfig:
    healthCheck:
      checkIntervalSec: 30
      timeoutSec: 10
      healthyThreshold: 1
      unhealthyThreshold: 3
      path: "/signin"
      port: 3000
      type: HTTP
  resources: {}
  # resources:
  #   limits:
  #     cpu: 3000m
  #     memory: 2Gi
  #   requests:
  #     cpu: 1500m
  #     memory: 512Mi
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 3
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80
  nodeSelector: {}
  topologySpreadConstraints: []
  tolerations: []
  affinity: {}
  healthCheck:
    enabled: false
    probes:
      livenessProbe:
        httpGet:
          path: /
          port: http
      readinessProbe:
        httpGet:
          path: /
          port: http

websocket:
  enabled: true
  env:
    - name: SOKETI_HOST
      value: "0.0.0.0"
    - name: SOKETI_DEBUG
      value: "1"
    - name: SOKETI_USER_AUTHENTICATION_TIMEOUT
      value: 3000
    - name: SOKETI_DEFAULT_APP_ID
      value: 1
    - name: SOKETI_DEFAULT_APP_KEY
      value: keepappkey
    - name: SOKETI_DEFAULT_APP_SECRET
      value: keepappsecret
  replicaCount: 1
  image:
    repository: quay.io/soketi/soketi
    pullPolicy: Always
    tag: "1.4-16-debian"
  imagePullSecrets: []
  serviceAccount:
    create: true
    annotations: {}
    name: ""
  podAnnotations: {}
  podSecurityContext: {}
  securityContext: {}
  service:
    type: ClusterIP
    port: 6001
  resources: {}
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 3
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80
  nodeSelector: {}
  topologySpreadConstraints: []
  tolerations: []
  affinity: {}
  healthCheck:
    enabled: false
    probes:
      livenessProbe:
        httpGet:
          path: /
          port: http
      readinessProbe:
        httpGet:
          path: /
          port: http
  # for openshit
  route:
    enabled: false
    host: chart-example.local
    wildcardPolicy: None
    tls: []

database:
  enabled: true
  # type: postgres  # can be 'mysql' or 'postgres'
  type: mysql
  replicaCount: 1
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1
  pv:
    enabled: true
    size: 5Gi
    storageClass: ""
  pvc:
    enabled: true
    size: 5Gi
    storageClass: ""
    retain: false
  image:
    # This will be overridden by type-specific settings
    repository: ""
    pullPolicy: IfNotPresent
    tag: "latest"
  mysql:
    image:
      repository: mysql
      tag: "latest"
    env:
      - name: MYSQL_ALLOW_EMPTY_PASSWORD
        value: true
      - name: MYSQL_DATABASE
        value: keep
      - name: MYSQL_PASSWORD
        value: null
    port: 3306
    dataDir: /var/lib/mysql
  postgres:
    image:
      repository: postgres
      tag: "latest"
    env:
      - name: POSTGRES_DB
        value: keep
      - name: POSTGRES_PASSWORD
        value: mysecretpassword
    port: 5432
    dataDir: /var/lib/postgresql/data
    config:
      maxConnections: 1000
      sharedBuffers: 256MB
  imagePullSecrets: []
  podAnnotations: {}
  podSecurityContext: {}
  securityContext: {}
  service:
    type: ClusterIP
  resources: {}
  # resources:
  #   requests:
  #     cpu: "2"
  #     memory: "4Gi"
  #   limits:
  #     cpu: "4"
  #     memory: "8Gi"
  autoscaling:
    enabled: false
  nodeSelector: {}
  tolerations: []
  affinity: {}
  healthCheck:
    enabled: false
    probes: {}
  extraVolumeMounts: []
  extraVolumes: []

# Add this new section before or after database section
deleteSecretJob:
  image:
    repository: bitnami/kubectl
    tag: latest
    pullPolicy: Always
